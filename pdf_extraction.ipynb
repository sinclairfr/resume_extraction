{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f53fedf-1dc4-4bc7-8c31-930b2093770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/medo/Resume CV extraction/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4ae762-ba8a-42e3-90ca-2c8eff874b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_path = \"BSV_VITI_LR_N01_22032022.pdf\"\n",
    "pdf_path = \"CV Mehdi Fekih.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68dfc7-504b-4469-9034-cf1ad23f800b",
   "metadata": {},
   "source": [
    "# PDF Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aeb8c1c-6fbd-44bf-812d-467f8d0ae2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b49f52-bcf3-42df-98a4-7b8cb295441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages, extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c07eaa2-588d-4046-9293-db897c69e151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "<LTTextBoxHorizontal(0) 237.824,801.721,358.204,823.721 'Mehdi Fekih\\n'>\n",
      "<LTTextBoxHorizontal(1) 204.424,759.911,391.608,785.161 '8 rue Bernard de Clairvaux, 75003 Paris\\n07 82 90 60 71 – mehdi.fekih@edhec.com\\n'>\n",
      "<LTTextBoxHorizontal(2) 28.800,730.234,200.169,742.234 '■ FORMATION ET DIPLÔMES\\n'>\n",
      "<LTTextBoxHorizontal(3) 40.800,704.087,60.794,714.087 '2022\\n'>\n",
      "<LTTextBoxHorizontal(4) 139.800,704.087,335.530,714.087 'Data Scientist, Titre RNCP de niveau 7 (Bac+5)\\n'>\n",
      "<LTTextBoxHorizontal(5) 40.800,680.087,90.782,690.087 '2005 – 2009\\n'>\n",
      "<LTTextBoxHorizontal(6) 139.800,668.087,502.511,690.087 'EDHEC BUSINESS SCHOOL, Master in Management – Campus de Lille\\nSpécialisation entrepreneuriat. English Track Program (scolarité entièrement en anglais).\\n'>\n",
      "<LTTextBoxHorizontal(7) 139.800,644.087,462.073,654.087 'Université Paris 7, Licence de Mathématiques Appliquées et Sciences Sociales.\\n'>\n",
      "<LTTextBoxHorizontal(8) 40.800,620.087,90.782,630.087 '2002 – 2004\\n'>\n",
      "<LTTextBoxHorizontal(9) 139.800,620.087,445.917,630.087 'Classe préparatoire aux Grandes Écoles de Commerce, voie scientifique.\\n'>\n",
      "<LTTextBoxHorizontal(10) 40.800,596.087,60.794,606.087 '2002\\n'>\n",
      "<LTTextBoxHorizontal(11) 40.800,572.087,76.910,582.087 'Langues\\n'>\n",
      "<LTTextBoxHorizontal(12) 139.800,596.087,470.722,606.087 'Baccalauréat Scientifique (spécialisation Mathématiques), mention AB – Chelles\\n'>\n",
      "<LTTextBoxHorizontal(13) 139.800,536.087,406.587,582.087 'Anglais : Courant (C1) -TOEFL IBT 111/120, TOEIC 980/1000\\nEspagnol : Niveau moyen (B2)\\nItalien : Notions (A2)\\nThaïlandais : Notions (A1)\\n'>\n",
      "<LTTextBoxHorizontal(14) 28.800,509.734,251.439,521.734 '■ EXPÉRIENCES PROFESSIONNELLES\\n'>\n",
      "<LTTextBoxHorizontal(15) 40.800,483.587,60.794,493.587 '2023\\n'>\n",
      "<LTTextBoxHorizontal(16) 139.800,483.587,511.451,493.587 'Co-fondateur - Data Scientist et Data Analyst, PME et industrie, Prismanalytics – Paris\\n'>\n",
      "<LTTextBoxHorizontal(17) 154.800,423.587,516.734,469.631 '● Analyse de données et performance des entreprises.\\n● Modélisation statistique et machine learning.\\n● Visualisation de données et tableaux de bord interactifs.\\n● Gestion de projet et développement de solutions personnalisées en Machine Learning.\\n'>\n",
      "<LTTextBoxHorizontal(18) 40.800,399.587,84.115,409.587 '2019-2021\\n'>\n",
      "<LTTextBoxHorizontal(19) 139.800,399.587,457.020,409.587 'Consultant, automatisation et sécurité, PME et industrie, freelance – Paris\\n'>\n",
      "<LTTextBoxHorizontal(20) 154.800,327.587,531.992,385.631 '● Mise en place d’outils de reporting automatisé via SAP Business Objects.\\n● Traitement et sécurisation des données sensibles (data wrangling, chiffrage, redondance).\\n● Solutions de gestion de télésurveillance via objets connectés (IoT) et traitement d’images.\\n● Pentesting interne et conseil en sécurisation de réseau, mise en place de VPN.\\n● Infogérance sur serveurs et docker.\\n'>\n",
      "<LTTextBoxHorizontal(21) 40.800,303.587,90.782,313.587 '2017 – 2019\\n'>\n",
      "<LTTextBoxHorizontal(22) 139.800,303.587,428.931,313.587 'Consultant E-commerce et Marketing digital, freelance – Thaïlande\\n'>\n",
      "<LTTextBoxHorizontal(23) 154.800,279.587,559.199,289.631 '● Mission de conseils dans l’e-commerce et le marketing digital (région de Bangkok), expertise en\\n'>\n",
      "<LTTextBoxHorizontal(24) 172.800,267.587,376.262,277.587 'stratégies de vente en ligne et de marketing digital.\\n'>\n",
      "<LTTextBoxHorizontal(25) 154.800,243.587,551.834,265.631 \"● Gestion des réservations en ligne Booking.com, Airbnb, Agoda pour compte de tiers.\\n● Mise en œuvre de techniques d'optimisation des moteurs de recherche (SEO) pour améliorer la\\n\">\n",
      "<LTTextBoxHorizontal(26) 172.800,231.587,244.707,241.587 'visibilité en ligne.\\n'>\n",
      "<LTTextBoxHorizontal(27) 154.800,219.587,480.655,229.631 '● Gestion des PNL pour augmenter les réservations directes et les conversions.\\n'>\n",
      "<LTTextBoxHorizontal(28) 40.800,195.587,90.782,205.587 '2016 – 2017\\n'>\n",
      "<LTTextBoxHorizontal(29) 139.800,195.587,415.293,205.587 'Consultant web et réseaux – Australie, région du New South Wales\\n'>\n",
      "<LTTextBoxHorizontal(30) 154.800,159.587,528.644,181.631 '● Développement web dans l’e-commerce.\\n● Mise en place de réseaux d’entreprises et de solutions de virtualisation (câblage de baies,\\n'>\n",
      "<LTTextBoxHorizontal(31) 172.800,147.587,309.940,157.587 'firewalls, virtualisation proxmox).\\n'>\n",
      "<LTTextBoxHorizontal(32) 154.800,135.587,385.418,145.631 '● Gestion de firewalls et de réseaux internes (pfSense).\\n'>\n",
      "<LTTextBoxHorizontal(33) 40.800,111.587,90.782,121.587 '2013 – 2016\\n'>\n",
      "<LTTextBoxHorizontal(34) 139.800,111.695,252.995,121.195 'Gestion immobilière – Paris\\n'>\n",
      "<LTTextBoxHorizontal(35) 154.800,88.337,528.278,98.381 \"● Gestion locative d'un parc immobilier pour location touristique à Paris et supervision des\\n\">\n",
      "<LTTextBoxHorizontal(36) 172.800,76.337,268.560,86.337 'chantiers de rénovation.\\n'>\n",
      "<LTTextBoxHorizontal(37) 154.800,64.337,561.561,74.381 \"● Prospection d'appartements pour acquéreurs étrangers, conseil en investissement immobilier haut\\n\">\n",
      "<LTTextBoxHorizontal(38) 172.800,52.337,424.099,62.337 'de gamme (>1M€) et budgétisation de chantiers de rénovation.\\n'>\n",
      "<LTRect 0.000,-0.250,595.500,842.000>\n",
      "<LTLine 32.000,720.500,563.000,720.500>\n",
      "<LTLine 32.000,499.500,563.000,499.500>\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for single_page_layout in extract_pages(pdf_path):\n",
    "    counter +=1\n",
    "    print(f'Page {counter}')\n",
    "    for elt in single_page_layout:\n",
    "        print(elt)\n",
    "    if counter == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c9867-3d2f-4262-9218-5995eeb6b1af",
   "metadata": {},
   "source": [
    "# pyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d31e546-ee76-41ba-a948-1e88a30f00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import PIL.Image\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20215761-46b4-4b31-a350-6d7e99c29741",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fitz.open(pdf_path)\n",
    "counter = 1\n",
    "page_counter = 0\n",
    "for i in range(len(pdf)):\n",
    "    page_counter += 1\n",
    "    page = pdf[i]\n",
    "    images = page.get_images()\n",
    "    for image in images:\n",
    "        base_img = pdf.extract_image(image[0])\n",
    "        image_data = base_img[\"image\"]\n",
    "        img = PIL.Image.open(io.BytesIO(image_data))\n",
    "        extension = base_img[\"ext\"]\n",
    "        folder = f'extracted_images/page_{page_counter}'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        img.save(open(f'{folder}/image{counter}.{extension}', \"wb\"))\n",
    "        counter += 1\n",
    "    if counter ==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60896f2a-3339-41ba-8ca6-200892be296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 0,\n",
       " 'type': 0,\n",
       " 'bbox': (237.82423400878906,\n",
       "  15.915508270263672,\n",
       "  358.20355224609375,\n",
       "  40.27878952026367),\n",
       " 'lines': [{'spans': [{'size': 22.0,\n",
       "     'flags': 20,\n",
       "     'font': 'TimesNewRomanPS-BoldMT',\n",
       "     'color': 5475540,\n",
       "     'ascender': 0.89111328125,\n",
       "     'descender': -0.21630859375,\n",
       "     'text': 'Mehdi Fekih',\n",
       "     'origin': (237.82423400878906, 35.52000045776367),\n",
       "     'bbox': (237.82423400878906,\n",
       "      15.915508270263672,\n",
       "      358.20355224609375,\n",
       "      40.27878952026367)}],\n",
       "   'wmode': 0,\n",
       "   'dir': (1.0, 0.0),\n",
       "   'bbox': (237.82423400878906,\n",
       "    15.915508270263672,\n",
       "    358.20355224609375,\n",
       "    40.27878952026367)}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'number': 1,\n",
       " 'type': 0,\n",
       " 'bbox': (204.42355346679688,\n",
       "  55.657752990722656,\n",
       "  391.6080322265625,\n",
       "  82.08938598632812),\n",
       " 'lines': [{'spans': [{'size': 11.0,\n",
       "     'flags': 4,\n",
       "     'font': 'TimesNewRomanPSMT',\n",
       "     'color': 0,\n",
       "     'ascender': 0.89111328125,\n",
       "     'descender': -0.21630859375,\n",
       "     'text': '8 rue Bernard de Clairvaux, 75003 Paris',\n",
       "     'origin': (209.33460998535156, 65.45999908447266),\n",
       "     'bbox': (209.33460998535156,\n",
       "      55.657752990722656,\n",
       "      386.69403076171875,\n",
       "      67.83939361572266)}],\n",
       "   'wmode': 0,\n",
       "   'dir': (1.0, 0.0),\n",
       "   'bbox': (209.33460998535156,\n",
       "    55.657752990722656,\n",
       "    386.69403076171875,\n",
       "    67.83939361572266)},\n",
       "  {'spans': [{'size': 11.0,\n",
       "     'flags': 4,\n",
       "     'font': 'TimesNewRomanPSMT',\n",
       "     'color': 0,\n",
       "     'ascender': 0.89111328125,\n",
       "     'descender': -0.21630859375,\n",
       "     'text': '07 82 90 60 71 – mehdi.fekih@edhec.com',\n",
       "     'origin': (204.42355346679688, 79.70999145507812),\n",
       "     'bbox': (204.42355346679688,\n",
       "      69.90774536132812,\n",
       "      391.6080322265625,\n",
       "      82.08938598632812)}],\n",
       "   'wmode': 0,\n",
       "   'dir': (1.0, 0.0),\n",
       "   'bbox': (204.42355346679688,\n",
       "    69.90774536132812,\n",
       "    391.6080322265625,\n",
       "    82.08938598632812)}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "count = 0\n",
    "for i, page in enumerate(doc):\n",
    "    ext = page.get_text(\"dict\")[\"blocks\"]\n",
    "    for elt in ext:\n",
    "        if elt[\"type\"] != 1:\n",
    "            count += 1\n",
    "            if count > 2:\n",
    "                break\n",
    "            display(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed480b2a-4c8f-431e-a59c-d7070f220a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43e3363-ded9-4b99-ad13-e5607ea16858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigtree import shift_nodes, Node, yield_tree, findall\n",
    "from bigtree import Node, preorder_iter, postorder_iter, levelorder_iter, levelordergroup_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2c9faa-8d40-4cf8-869f-53fa604f9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from typing_extensions import Self\n",
    "import os\n",
    "from os.path import basename\n",
    "import re\n",
    "import logging\n",
    "from typing import Iterable, Sequence\n",
    "\n",
    "\n",
    "# formatting-related constants for pretty-printing\n",
    "SHORT_FORMAT_SPEC = \"short\"\n",
    "FULL_FORMAT_SPEC = \"full\"\n",
    "FILTERED_METADATA_KEYS = [\"font\", \"size\", \"width\", \"height\", \"format\", \"color\"]\n",
    "\n",
    "#: label to classify nodes\n",
    "NODE_TYPE_LABEL = \"node_type\"\n",
    "NODE_TYPE_DOCUMENT = \"DOCUMENT\"\n",
    "NODE_TYPE_PAGE = \"PAGE\"\n",
    "NODE_TYPE_LINE = \"LINE\"\n",
    "NODE_TYPE_SPAN = \"SPAN\"\n",
    "NODE_TYPE_IMAGE = \"IMAGE\"\n",
    "NODE_TYPE_TABLE = \"TABLE\"\n",
    "\n",
    "class PdfContent(Node):\n",
    "    \"\"\"\n",
    "    Holds content extracted from a PDF file as a tree structure.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str,\n",
    "                 text: str = None,\n",
    "                 image: bytearray = None,\n",
    "                 table: DataFrame = None,\n",
    "                 metadata: dict = None,\n",
    "                 labels: dict = None,\n",
    "                 parent: Self = None):\n",
    "        \"\"\"\n",
    "        Builds a new PdfContent based on either text or an image.\n",
    "\n",
    "        :param name: (inherited) a unique label for the content node\n",
    "        :param parent: (inherited) a parent PdfContent, if not the whole PDF file itself (i.e. the tree's root)\n",
    "        :param text: some text read from the PDF\n",
    "        :param image: an image extracted from the PDF\n",
    "        :param metadata: a dict of misc metadata about the text/image source\n",
    "        :param labels: a dict of metadata about the text/image with semantic value for processing (e.g. classifiers)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(name, parent=parent, text=text, image=image, table=table, labels=labels, metadata=metadata)\n",
    "\n",
    "    def is_typed(self, node_type: str) -> bool:\n",
    "        return self.labels[NODE_TYPE_LABEL] == node_type\n",
    "\n",
    "    def __format__(self, format_spec) -> str:\n",
    "        \"\"\"\n",
    "        Print format of this PdfContent.\n",
    "        The \"full\" format_spec displays all metadata. The \"short\" one displays no metadata at all.\n",
    "\n",
    "        :return: a printable representation of the PDF\n",
    "        \"\"\"\n",
    "\n",
    "        def printable_text(n: PdfContent) -> str:\n",
    "            if n.is_typed(NODE_TYPE_LINE) or n.is_typed(NODE_TYPE_TABLE):\n",
    "                return n.text\n",
    "            if n.is_typed(NODE_TYPE_IMAGE) and format_spec == FULL_FORMAT_SPEC:\n",
    "                return to_ascii(n.image)\n",
    "            if format_spec != SHORT_FORMAT_SPEC:\n",
    "                return n.text\n",
    "            return ''\n",
    "\n",
    "        def printable_metadata(n: PdfContent) -> str:\n",
    "            if n.metadata is None or format_spec == SHORT_FORMAT_SPEC:\n",
    "                return ''\n",
    "            if format_spec == FULL_FORMAT_SPEC:\n",
    "                return \"{}\".format(n.metadata)\n",
    "            return \"{}\".format({k: v for k, v in n.metadata.items() if k in FILTERED_METADATA_KEYS})\n",
    "\n",
    "        return \"\\n\".join([\n",
    "            \"{}{}[{}] {} {}\".format(branch, stem, node.node_name, printable_text(node), printable_metadata(node))\n",
    "            for branch, stem, node in yield_tree(self, style=\"const\")\n",
    "            if format_spec != SHORT_FORMAT_SPEC or not node.is_typed(NODE_TYPE_SPAN)\n",
    "        ])\n",
    "\n",
    "    def find_nodes(self, *node_types) -> list[Self]:\n",
    "        \"\"\"\n",
    "        Returns all sub-nodes of the given type(s).\n",
    "        :return: a tuple of PdfContents\n",
    "        \"\"\"\n",
    "        return list(findall(self, condition=lambda node: node.labels[NODE_TYPE_LABEL] in node_types))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5820d7d-d8b6-419d-ba8d-c66894250296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path) -> PdfContent:\n",
    "    \"\"\"\n",
    "    Reads a source PDF file as a PdfContent.\n",
    "    The returned data structure is pre-processed: its content is as clean as possible to ease actual processing.\n",
    "\n",
    "    :param file_path: source PDF path on the file system\n",
    "    \"\"\"\n",
    "\n",
    "    with fitz.open(file_path) as doc:\n",
    "        root_node = PdfContent(name=basename(file_path),\n",
    "                               labels={NODE_TYPE_LABEL: NODE_TYPE_DOCUMENT},\n",
    "                               metadata=doc.metadata)\n",
    "        for page in doc:\n",
    "            blocks_list = page.get_text(\"dict\", sort=True)[\"blocks\"]\n",
    "            page_node = PdfContent(name=f\"page-{page.number}\",\n",
    "                                   parent=root_node,\n",
    "                                   metadata={\"page_idx\": page.number},\n",
    "                                   labels={NODE_TYPE_LABEL: NODE_TYPE_PAGE},\n",
    "                                   text=f\"{len(blocks_list)} blocks\")\n",
    "            for block_idx, block in enumerate(blocks_list):\n",
    "                if \"image\" in block:\n",
    "                    image = bytearray(block[\"image\"])\n",
    "                    image_metadata = {k: v for k, v in block.items() if k != \"image\"} | {\"block_idx\": block_idx}\n",
    "                    PdfContent(name=f\"img-{page.number}.{block_idx}\",\n",
    "                               parent=page_node,\n",
    "                               labels={NODE_TYPE_LABEL: NODE_TYPE_IMAGE},\n",
    "                               image=image,\n",
    "                               metadata=image_metadata)\n",
    "                if \"lines\" in block:\n",
    "                    for line_idx, line in enumerate(block[\"lines\"]):\n",
    "                        spans = [span[\"text\"] for span in line[\"spans\"]]\n",
    "                        line_metadata = {k: v for k, v in line.items() if k != \"spans\"} | {\"block_idx\": block_idx}\n",
    "                        line_node = PdfContent(name=f\"line-{page.number}.{block_idx}.{line_idx}\",\n",
    "                                               parent=page_node,\n",
    "                                               labels={NODE_TYPE_LABEL: NODE_TYPE_LINE},\n",
    "                                               text=''.join(spans),\n",
    "                                               metadata=line_metadata)\n",
    "                        for span_idx, span in enumerate(line[\"spans\"]):\n",
    "                            PdfContent(name=f\"span-{page.number}.{block_idx}.{line_idx}.{span_idx}\",\n",
    "                                       parent=line_node,\n",
    "                                       labels={NODE_TYPE_LABEL: NODE_TYPE_SPAN},\n",
    "                                       text=span[\"text\"],\n",
    "                                       metadata={k: v for k, v in span.items() if k != \"text\"})\n",
    "\n",
    "        sanitize(root_node, doc)\n",
    "    return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a826884d-dc4f-4128-b602-1afdd2cebb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_empty_lines(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Modify the given PdfContent in place, removing all empty lines.\n",
    "    :param pdf: a root PdfContent\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for line in pdf.find_nodes(NODE_TYPE_LINE):\n",
    "        if re.fullmatch(\" *\", line.text):\n",
    "            shift_nodes(pdf, [line.path_name], [None])\n",
    "            count += 1\n",
    "    logging.debug(f\"removed {count} empty lines\")\n",
    "\n",
    "\n",
    "def prune_spans(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Modify the given PdfContent in place, removing all spans.\n",
    "    :param pdf: a root PdfContent\n",
    "    \"\"\"\n",
    "    for span in pdf.find_nodes(NODE_TYPE_SPAN):\n",
    "        shift_nodes(pdf, [span.path_name], [None])\n",
    "\n",
    "\n",
    "def prune_footers(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Search for footers in the given PDF and remove them in place.\n",
    "    Assume each page may finish with a same footer block, differing from at most a page number.\n",
    "    :param pdf: a multi-pages PDF document\n",
    "    \"\"\"\n",
    "    footers: list[tuple[str, list[PdfContent]]] = []  # tuples with concatenated text content & nodes\n",
    "    for page in pdf.find_nodes(NODE_TYPE_PAGE):\n",
    "        last_block_idx = max([line.metadata[\"block_idx\"] for line in page.find_nodes(NODE_TYPE_LINE)])\n",
    "        last_lines = [line for line in page.find_nodes(NODE_TYPE_LINE) if line.metadata[\"block_idx\"] == last_block_idx]\n",
    "        footers.append((\"\\t\".join([line.text for line in last_lines]), last_lines))\n",
    "\n",
    "    for footer in footers:\n",
    "        # compare with other text contents\n",
    "        diff_list = [edit_distance(footer[0], f[0]) for f in footers if f[1] != footer[1]]\n",
    "        # ignore outliers\n",
    "        max_outliers = min(len(footers) - 1, FOOTER_MAX_OUTLIERS)  # keep 1+ elements\n",
    "        for i in range(max_outliers):\n",
    "            diff_list.remove(max(diff_list))\n",
    "        # remove nodes with same content as others\n",
    "        if len(diff_list) > 0 and max(diff_list) <= FOOTER_DISTANCE_THRESHOLD:\n",
    "            logging.debug(f\"removed footer at {[f.path_name for f in footer[1]]}: {footer[0]}\")\n",
    "            shift_nodes(pdf, [f.path_name for f in footer[1]], [None] * len(footer[1]))\n",
    "def infer_line_format(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Enrich lines metadata in place, with \"font\" and \"size\" attributes, based on children spans.\n",
    "    The font is the most used one; the size is the biggest one.\n",
    "    :param pdf: some PdfContent\n",
    "    \"\"\"\n",
    "    for line in pdf.find_nodes(NODE_TYPE_LINE):\n",
    "        line_spans = line.find_nodes(NODE_TYPE_SPAN)\n",
    "        line.metadata[\"font\"] = most_used_metadata(line_spans, normalize_font)\n",
    "        line.metadata[\"size\"] = max([normalize_size(span) for span in line.find_nodes(NODE_TYPE_SPAN)])\n",
    "\n",
    "def infer_line_format(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Enrich lines metadata in place, with \"font\" and \"size\" attributes, based on children spans.\n",
    "    The font is the most used one; the size is the biggest one.\n",
    "    :param pdf: some PdfContent\n",
    "    \"\"\"\n",
    "    for line in pdf.find_nodes(NODE_TYPE_LINE):\n",
    "        line_spans = line.find_nodes(NODE_TYPE_SPAN)\n",
    "        line.metadata[\"font\"] = most_used_metadata(line_spans, normalize_font)\n",
    "        line.metadata[\"size\"] = max([normalize_size(span) for span in line.find_nodes(NODE_TYPE_SPAN)])\n",
    "\n",
    "\n",
    "def most_used_metadata(contents: Iterable[PdfContent], metadata_getter):\n",
    "    \"\"\"\n",
    "    Select one of the most used metadata in the given content.\n",
    "    :param contents: collection of contents to parse\n",
    "    :param metadata_getter: how to extract the metadata to compare\n",
    "    :return: the most used value, or None if none was found\n",
    "    \"\"\"\n",
    "    values_length: dict[int | None] = {None: 0}\n",
    "    for content in contents:\n",
    "        value = metadata_getter(content)\n",
    "        text_length = len(content.text)\n",
    "        values_length.setdefault(value, 0)\n",
    "        values_length[value] += text_length\n",
    "    main_font_length = max(values_length.values())\n",
    "    return [k for k, v in values_length.items() if v == main_font_length][0]\n",
    "\n",
    "\n",
    "def merge_similar_sibling_lines(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Modifies the given PdfContent in place,\n",
    "    merging sibling lines when coming from the same block or having similar format.\n",
    "    :param pdf: a PdfContent with content to merge\n",
    "    \"\"\"\n",
    "    all_pages = list(pdf.find_nodes(NODE_TYPE_PAGE))\n",
    "    for page in all_pages:\n",
    "        # create a new page container\n",
    "        new_page = PdfContent(name=f\"{page.node_name}-merged\",\n",
    "                              parent=pdf,\n",
    "                              labels={NODE_TYPE_LABEL: NODE_TYPE_PAGE},\n",
    "                              metadata=page.metadata)\n",
    "\n",
    "        # mark mergeable lines (to the right)\n",
    "        mergeable_lines = [\n",
    "            child.is_typed(NODE_TYPE_LINE) and child.right_sibling is not None\n",
    "            and child.right_sibling.is_typed(NODE_TYPE_LINE) and same_format(child, child.right_sibling)\n",
    "            for child in page.children\n",
    "        ]\n",
    "\n",
    "        i = -1\n",
    "        j = 0\n",
    "        while j < len(mergeable_lines):\n",
    "            if not mergeable_lines[j]:  # end of mergeable sub-list\n",
    "                if i < j - 1:\n",
    "                    source_lines = page.children[0:j - i]\n",
    "                    # create an aggregating line in the new page\n",
    "                    new_line = PdfContent(name=f\"{source_lines[0].node_name}-{source_lines[-1].node_name}\",\n",
    "                                          parent=new_page,\n",
    "                                          text=re.sub(\" +\", \" \", \" \".join([line.text for line in source_lines])),\n",
    "                                          labels={NODE_TYPE_LABEL: NODE_TYPE_LINE},\n",
    "                                          metadata={\n",
    "                                              \"sources\": {s.node_name: s.metadata for s in source_lines},\n",
    "                                              \"font\": normalize_font(source_lines[0]),\n",
    "                                              \"size\": normalize_size(source_lines[0]),\n",
    "                                          })\n",
    "                    # migrate children and remove merged lines\n",
    "                    for source_line in source_lines:\n",
    "                        for child in source_line.children:\n",
    "                            shift_nodes(pdf, [child.path_name], [f\"{new_line.path_name}/{child.node_name}\"])\n",
    "                        shift_nodes(pdf, [source_line.path_name], [None])\n",
    "                else:\n",
    "                    unchanged_line = page.children[0]\n",
    "                    shift_nodes(pdf, [unchanged_line.path_name], [f\"{new_page.path_name}/{unchanged_line.node_name}\"])\n",
    "                i = j\n",
    "            j += 1\n",
    "\n",
    "        # cleanup\n",
    "        shift_nodes(pdf, [page.path_name], [None])\n",
    "\n",
    "\n",
    "def infer_titles(pdf: PdfContent):\n",
    "    \"\"\"\n",
    "    Modifies the given PdfContent in place, introducing a line hierarchy based on font size.\n",
    "    Images are always considered a direct subsection of their predecessor node.\n",
    "    :param pdf: a whole PdfContent\n",
    "    \"\"\"\n",
    "\n",
    "    # no hierarchy below the main font size\n",
    "    main_font_size = most_used_metadata(pdf.find_nodes(NODE_TYPE_LINE), normalize_size)\n",
    "\n",
    "    for image in pdf.find_nodes(NODE_TYPE_IMAGE):\n",
    "        if image.left_sibling is not None and image.left_sibling.is_typed(NODE_TYPE_LINE):\n",
    "            shift_nodes(pdf, [image.path_name], [f\"{image.left_sibling.path_name}/{image.node_name}\"])\n",
    "\n",
    "    all_lines = [line for line in pdf.find_nodes(NODE_TYPE_LINE, NODE_TYPE_TABLE)]\n",
    "    for line in all_lines:\n",
    "        while is_subsection(line, main_font_size):\n",
    "            shift_nodes(pdf, [line.path_name], [f\"{line.left_sibling.path_name}/{line.node_name}\"])\n",
    "\n",
    "\n",
    "def is_subsection(line: PdfContent, main_font_size: float) -> bool:\n",
    "    \"\"\"\n",
    "    Tells if the given line is a subsection of its left sibling.\n",
    "    :param line: a line\n",
    "    :param main_font_size: the font size titles should exceed\n",
    "    :return: if the given line should be a subsection of its left sibling\n",
    "    \"\"\"\n",
    "    sibling = line.left_sibling\n",
    "    if sibling is None or not sibling.is_typed(NODE_TYPE_LINE) or normalize_size(sibling) <= main_font_size:\n",
    "        return False\n",
    "    return normalize_size(line) < normalize_size(sibling)\n",
    "\n",
    "\n",
    "def normalize_size(content: PdfContent) -> (float, None):\n",
    "    \"\"\"\n",
    "    Normalize the given node's size in order to compare values more leniently.\n",
    "    :param content: some PdfContent\n",
    "    :return: a comparable, rounded size; or None if not applicable\n",
    "    \"\"\"\n",
    "    raw_size = content.metadata[\"size\"] if \"size\" in content.metadata else None\n",
    "    if raw_size is None:\n",
    "        return None\n",
    "    return round(float(raw_size) * 4, 0) / 4  # rounded to 0.25\n",
    "\n",
    "\n",
    "def normalize_font(content: PdfContent) -> (str, None):\n",
    "    \"\"\"\n",
    "    Normalize the given node's font name in order to compare values more leniently.\n",
    "    :param content: some PdfContent\n",
    "    :return: a simpler, comparable font name; or None if not applicable\n",
    "    \"\"\"\n",
    "    raw_font = content.metadata[\"font\"] if \"font\" in content.metadata else None\n",
    "    if raw_font is None:\n",
    "        return None\n",
    "    return re.sub(\"-(Bold|Italic|Black|Regular)+|MT\\\\b|PS\\\\b\", \"\", raw_font)  # ignore modifiers & suffixes\n",
    "\n",
    "\n",
    "def same_format(content1: PdfContent, content2: PdfContent) -> bool:\n",
    "    \"\"\"\n",
    "    Returns if the given PdfContents have similar text formatting.\n",
    "    :param content1: some content\n",
    "    :param content2: another content\n",
    "    :return: if the given contents are similar, formatting-wise; or None if not comparable\n",
    "    \"\"\"\n",
    "    font1 = normalize_font(content1)\n",
    "    font2 = normalize_font(content2)\n",
    "    size1 = normalize_size(content1)\n",
    "    size2 = normalize_size(content2)\n",
    "    if font1 is None or font2 is None or size1 is None or size2 is None:\n",
    "        return False\n",
    "    same_font = font1 == font2\n",
    "    same_font_size = abs(size1 - size2) < .5\n",
    "    return same_font and same_font_size\n",
    "\n",
    "\n",
    "def to_ascii(image: bytearray) -> str:\n",
    "    \"\"\"\n",
    "    Provides a textual, terminal-compatible view of the given image.\n",
    "    For debug purposes only.\n",
    "\n",
    "    :param image: any image\n",
    "    :return: a colored ASCII-art image\n",
    "    \"\"\"\n",
    "\n",
    "    temp_file = tempfile.NamedTemporaryFile(prefix=\"unibsv-\", delete=False)\n",
    "    with temp_file:\n",
    "        temp_file.write(image)\n",
    "    ascii_art = AsciiArt.from_image(temp_file.name).to_ascii(columns=100)\n",
    "    os.unlink(temp_file.name)\n",
    "    return \"\\n\" + ascii_art\n",
    "\n",
    "def merge_all_pages(pdf) -> PdfContent:\n",
    "    \"\"\"\n",
    "    Modifies the given PdfContent in place, merging all pages into a new one.\n",
    "    :param pdf: a root PdfContent with pages\n",
    "    :return: the new page with all content\n",
    "    \"\"\"\n",
    "    all_pages = [page for page in pdf.find_nodes(NODE_TYPE_PAGE)]\n",
    "\n",
    "    # add a new page as container\n",
    "    single_page = PdfContent(name=\"single-page\",\n",
    "                             parent=pdf,\n",
    "                             labels={NODE_TYPE_LABEL: NODE_TYPE_PAGE},\n",
    "                             metadata={\"sources\": {page.node_name: page.metadata for page in all_pages}})\n",
    "\n",
    "    # move all children\n",
    "    for page in all_pages:\n",
    "        for from_line in page.children:\n",
    "            shift_nodes(pdf, [from_line.path_name], [f\"{single_page.path_name}/{from_line.node_name}\"])\n",
    "\n",
    "    # cleanup\n",
    "    for page in all_pages:\n",
    "        shift_nodes(pdf, [page.path_name], [None])\n",
    "\n",
    "    logging.debug(f\"merged {len(all_pages)} pages\")\n",
    "    return single_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d26d2a2-52b7-46b8-a0da-c1ced3f90451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(pdf: PdfContent, doc: fitz.Document):\n",
    "    \"\"\"\n",
    "    Process in place the given PdfContent to ensure it's in a convenient format for further processing.\n",
    "    * Based on font/size metadata, aggregate spans and lines into paragraphs\n",
    "    * Include tables whenever possible\n",
    "    * Remove useless lines whenever possible (e.g. footers)\n",
    "    * Infer a title/section hierarchy based on font size and line order\n",
    "    * Simplify the tree structure (single page and no spans)\n",
    "    :param pdf: a raw PdfContent\n",
    "    :param doc: the source document (must not be closed yet, to enable extracting additional content)\n",
    "    \"\"\"\n",
    "\n",
    "    prune_empty_lines(pdf)\n",
    "    infer_line_format(pdf)\n",
    "    prune_spans(pdf)  # at this point spans are not useful anymore\n",
    "    #prune_footers(pdf)\n",
    "    #substitute_tables(pdf, doc)\n",
    "    merge_all_pages(pdf)\n",
    "    #merge_similar_sibling_lines(pdf)\n",
    "    infer_titles(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4395723-334a-4ce8-a671-28bf5c33376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = read_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b055013-d0b9-4ec7-a498-428b8ef93607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in preorder_iter(pdf):\n",
    "    break\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dbc572-a6b1-4b60-b4b2-6b5887ae4f42",
   "metadata": {},
   "source": [
    "# Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91a6ec-192f-4cb9-8088-30c7230a6660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfff9693-bf1b-4acf-b139-1a9eed7b752a",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c570b847-13c3-43da-a68f-0c86e10f613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "Running on public URL: https://f235a19b7e4f071c38.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f235a19b7e4f071c38.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/gradio/e85f62cb2da7d7af944bfbbda1a7bbdfa3ba3bb0/livraison.png\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import shutil\n",
    "\n",
    "UPLOAD_DIR = \"uploads\"  # Directory to save the uploaded files\n",
    "\n",
    "# Create the upload directory if it doesn't exist\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "def upload_file(file):\n",
    "    file_path = os.path.join(UPLOAD_DIR, file.name)\n",
    "    shutil.move(file_path, UPLOAD_DIR)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    file_output = gr.File()\n",
    "    upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"pdf\", \"doc\"], file_count=\"single\")\n",
    "    upload_button.upload(upload_file, upload_button, file_output)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "resume"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
